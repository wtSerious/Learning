{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "sys.path.append(\"E:/JupyterEnviroment/Learning/MachineLearning/Network/cs231n/classifiers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.layers import *\n",
    "from fc_net import *\n",
    "from cs231n.solver import *\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 49000) loss: 2.323437\n",
      "(Iteration 1 / 49000) loss: 2.323437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\JupyterEnviroment\\Learning\\MachineLearning\\Network\\cs231n\\layers.py:129: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(np.log([probs[np.arange(N),y]]))/N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 101 / 49000) loss: inf\n",
      "(Iteration 201 / 49000) loss: inf\n",
      "(Iteration 301 / 49000) loss: inf\n",
      "(Iteration 401 / 49000) loss: inf\n",
      "(Iteration 501 / 49000) loss: inf\n",
      "(Iteration 601 / 49000) loss: inf\n",
      "(Iteration 701 / 49000) loss: inf\n",
      "(Iteration 801 / 49000) loss: inf\n",
      "(Iteration 901 / 49000) loss: inf\n",
      "(Iteration 1001 / 49000) loss: inf\n",
      "(Iteration 1101 / 49000) loss: inf\n",
      "(Iteration 1201 / 49000) loss: inf\n",
      "(Iteration 1301 / 49000) loss: inf\n",
      "(Iteration 1401 / 49000) loss: inf\n",
      "(Iteration 1501 / 49000) loss: inf\n",
      "(Iteration 1601 / 49000) loss: inf\n",
      "(Iteration 1701 / 49000) loss: inf\n",
      "(Iteration 1801 / 49000) loss: inf\n",
      "(Iteration 1901 / 49000) loss: inf\n",
      "(Iteration 2001 / 49000) loss: inf\n",
      "(Iteration 2101 / 49000) loss: inf\n",
      "(Iteration 2201 / 49000) loss: inf\n",
      "(Iteration 2301 / 49000) loss: inf\n",
      "(Iteration 2401 / 49000) loss: inf\n",
      "(Iteration 2501 / 49000) loss: inf\n",
      "(Iteration 2601 / 49000) loss: inf\n",
      "(Iteration 2701 / 49000) loss: inf\n",
      "(Iteration 2801 / 49000) loss: inf\n",
      "(Iteration 2901 / 49000) loss: inf\n",
      "(Iteration 3001 / 49000) loss: inf\n",
      "(Iteration 3101 / 49000) loss: inf\n",
      "(Iteration 3201 / 49000) loss: inf\n",
      "(Iteration 3301 / 49000) loss: inf\n",
      "(Iteration 3401 / 49000) loss: inf\n",
      "(Iteration 3501 / 49000) loss: inf\n",
      "(Iteration 3601 / 49000) loss: inf\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(reg=1e-1)\n",
    "solver = None\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "solver = Solver(model, data,\n",
    "    update_rule='sgd_momentum',\n",
    "    optim_config={\n",
    "    'learning_rate': 1e-3,\n",
    "    },\n",
    "    lr_decay=0.8,\n",
    "    num_epochs=10, batch_size=100,\n",
    "    print_every=100)\n",
    "solver.train()\n",
    "scores = model.loss(data['X_test'])\n",
    "y_pred = np.argmax(scores, axis = 1)\n",
    "acc = np.mean(y_pred == data['y_test'])\n",
    "print ('test acc: %f' %(acc))\n",
    "#pass\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
