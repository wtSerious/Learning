{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as Mapping\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL  import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as Mapping\n",
    "import numpy as np\n",
    "from PIL  import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_Face(Dataset):\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False,number=10000):\n",
    "        \"dir_path:文件路径\"\n",
    "        super(load_Face,self).__init__()\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        epoch = 0\n",
    "        for filename in os.listdir(root):\n",
    "            if epoch >=number:\n",
    "                break\n",
    "            img_path = os.path.join(root,filename)\n",
    "            with open(img_path,'rb') as f:\n",
    "                img = Mapping.imread(f)\n",
    "#                 img = (img/255.0)\n",
    "                self.data.append(img)\n",
    "            epoch +=1\n",
    "        self.targets = [1 for i in range(len(self.data))]\n",
    "        self.data = np.array(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img,target = self.data[index],self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            img = img.permute(1,2,0)\n",
    "        return img,target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"C:/Users/wtser/Desktop/learnData/data/faces/\"\n",
    "transform = T.Compose([T.Scale(64),T.ToTensor()])\n",
    "train_data = load_Face(root =dir_path,number = 2000,transform=transform)\n",
    "device = torch.device('cuda')\n",
    "loader_train = DataLoader(train_data,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for x,y in loader_train:\n",
    "    data.append(x.numpy())\n",
    "# data = torch.tensor(data)\n",
    "# data  = data.reshape(-1,64,64,3)\n",
    "# device = torch.device('cuda')\n",
    "# data  = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "x = data[:,:,:,0].flatten()\n",
    "x = x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192000,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "stand = StandardScaler()\n",
    "x = stand.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1870179\n"
     ]
    }
   ],
   "source": [
    "print(np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.std(data[:,:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Load_faces.ipynb to python\n",
      "[NbConvertApp] Writing 1403 bytes to Load_faces.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python Load_faces.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
