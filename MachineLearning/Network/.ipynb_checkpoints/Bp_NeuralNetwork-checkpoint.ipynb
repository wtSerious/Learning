{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits #手写数字数据集\n",
    "from sklearn.preprocessing import LabelBinarizer #标签二值化处理\n",
    "from sklearn.model_selection import train_test_split #训练和测试集分隔\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split #训练和测试集分隔\n",
    "# 载入数据\n",
    "digits = load_digits()\n",
    "\n",
    "# 输入的数据\n",
    "X = digits.data\n",
    "X = X.reshape([X.shape[0],-1])\n",
    "# 标签数据\n",
    "T = digits.target\n",
    "# 数据切分，默认测试集占0.25\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,T)\n",
    "# (1797,) [0 1]\n",
    "labels_train = LabelBinarizer().fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 10)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,layers,alpha=0.1):\n",
    "        self.W = []\n",
    "        self.layers = layers\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        #为隐藏层初始化权重\n",
    "        for i in range(0,len(layers)-2):\n",
    "            w = np.random.randn(layers[i]+1,layers[i+1]+1)\n",
    "            self.W.append(w/np.sqrt(layers[i]))\n",
    "            \n",
    "        w = np.random.randn(layers[-2]+1,layers[-1])\n",
    "        self.W.append(w/np.sqrt(layers[-2]))\n",
    "    \n",
    "    def softMax(self,x):\n",
    "        max_dict = [ [np.max(i)] for i in value]\n",
    "        x = np.exp((value-max_dict))\n",
    "        \n",
    "        return np.array([ i/np.sum(i) for i in x])\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self,x):\n",
    "        return x*(1-x)\n",
    "    \n",
    "    def fit(self,X,y,epochs = 1000,displayUpdate = 100,batch_size=1.0):\n",
    "        X = np.c_[X,np.ones((X.shape[0]))]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = np.random.choice(X.shape[0],batch_size,True)\n",
    "            batch_X = X[batch_index,:]\n",
    "            batch_Y = y[batch_index]\n",
    "#             self.fit_partial(batch_X,batch_Y,batch_size)\n",
    "            self.fit_partial_likehood(batch_X,batch_Y,batch_size)\n",
    "    \n",
    "            if epoch == 0 or (epoch+1)%displayUpdate==0:\n",
    "#                 loss = self.calculate_loss(X,y)\n",
    "                loss = self.calculate_loss_likehood(X,y)\n",
    "                print(\"[INFO] epoch={},loss={:.7f}\".format(epoch+1,loss))\n",
    "    \n",
    "    def fit_partial_likehood(self,x,y,batch_size):\n",
    "        A = [np.atleast_2d(x)]\n",
    "        for layer in range(len(self.W)):\n",
    "            net = A[layer].dot(self.W[layer])\n",
    "            \n",
    "            out = self.sigmoid(net)\n",
    "            \n",
    "            A.append(out)\n",
    "        \n",
    "        #计算输出层的梯度\n",
    "        D = [A[-1]-y]\n",
    "#         print('D',D)\n",
    "        for layer in np.arange(len(A)-2,0,-1):\n",
    "            delta = D[-1].dot(self.W[layer].T)\n",
    "            delta = delta*self.sigmoid_deriv(A[layer])\n",
    "            D.append(delta)\n",
    "        \n",
    "        D = D[::-1]\n",
    "        \n",
    "        for layer in range(len(self.W)):\n",
    "            self.W[layer] -= 1.0/batch_size*self.alpha*A[layer].T.dot(D[layer])\n",
    "    \n",
    "    def fit_partial(self,x,y,batch_size):\n",
    "        A = [np.atleast_2d(x)]\n",
    "        for layer in range(len(self.W)):\n",
    "            net = A[layer].dot(self.W[layer])\n",
    "            \n",
    "            out = self.sigmoid(net)\n",
    "            \n",
    "            A.append(out)\n",
    "            \n",
    "        error = A[-1] - y\n",
    "        \n",
    "        D = [error*self.sigmoid_deriv(A[-1])]\n",
    "\n",
    "        for layer in np.arange(len(A)-2,0,-1):\n",
    "            delta = D[-1].dot(self.W[layer].T)\n",
    "            delta = delta * self.sigmoid_deriv(A[layer])\n",
    "            \n",
    "            D.append(delta)\n",
    "        \n",
    "        D = D[::-1]\n",
    "        \n",
    "        for layer in range(len(self.W)):\n",
    "            self.W[layer]+= -1.0/batch_size*self.alpha*A[layer].T.dot(D[layer])\n",
    "            \n",
    "    def predict(self,x,addBias=True):\n",
    "        p = x\n",
    "        \n",
    "        if addBias ==True:\n",
    "            p = np.c_[p,np.ones((p.shape[0]))]\n",
    "        for i in range(len(self.layers)-1):\n",
    "            print(i)\n",
    "            p =self.sigmoid(p.dot(self.W[i]))\n",
    "        return p\n",
    "    \n",
    "    def calculate_loss(self,X,targets):\n",
    "        targets = np.atleast_2d(targets)\n",
    "        \n",
    "        predictions = self.predict(X,False)\n",
    "        loss = 0.5*np.sum((predictions-targets)**2)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def calculate_loss_likehood(self,X,y):\n",
    "        predictions = self.predict(X,False)\n",
    "        loss = -sum(np.sum(y*np.log(predictions),1))\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "[INFO] epoch=1,loss=2216.1546090\n",
      "0\n",
      "1\n",
      "[INFO] epoch=10,loss=2948.4871728\n",
      "0\n",
      "1\n",
      "[INFO] epoch=20,loss=2775.5421803\n",
      "0\n",
      "1\n",
      "[INFO] epoch=30,loss=2740.8123976\n",
      "0\n",
      "1\n",
      "[INFO] epoch=40,loss=2561.8688120\n",
      "0\n",
      "1\n",
      "[INFO] epoch=50,loss=2364.2870983\n",
      "0\n",
      "1\n",
      "[INFO] epoch=60,loss=2215.5286986\n",
      "0\n",
      "1\n",
      "[INFO] epoch=70,loss=2272.1193032\n",
      "0\n",
      "1\n",
      "[INFO] epoch=80,loss=2135.5523106\n",
      "0\n",
      "1\n",
      "[INFO] epoch=90,loss=2050.6384005\n",
      "0\n",
      "1\n",
      "[INFO] epoch=100,loss=1928.9495789\n",
      "0\n",
      "1\n",
      "[INFO] epoch=110,loss=1848.1560927\n",
      "0\n",
      "1\n",
      "[INFO] epoch=120,loss=1815.5265260\n",
      "0\n",
      "1\n",
      "[INFO] epoch=130,loss=1651.8575036\n",
      "0\n",
      "1\n",
      "[INFO] epoch=140,loss=1671.7627200\n",
      "0\n",
      "1\n",
      "[INFO] epoch=150,loss=1604.0657137\n",
      "0\n",
      "1\n",
      "[INFO] epoch=160,loss=1593.1792270\n",
      "0\n",
      "1\n",
      "[INFO] epoch=170,loss=1325.7564544\n",
      "0\n",
      "1\n",
      "[INFO] epoch=180,loss=1518.4386864\n",
      "0\n",
      "1\n",
      "[INFO] epoch=190,loss=1367.9882539\n",
      "0\n",
      "1\n",
      "[INFO] epoch=200,loss=1376.9694782\n",
      "0\n",
      "1\n",
      "[INFO] epoch=210,loss=1232.4933303\n",
      "0\n",
      "1\n",
      "[INFO] epoch=220,loss=1225.9270951\n",
      "0\n",
      "1\n",
      "[INFO] epoch=230,loss=1126.8543958\n",
      "0\n",
      "1\n",
      "[INFO] epoch=240,loss=999.6844089\n",
      "0\n",
      "1\n",
      "[INFO] epoch=250,loss=1018.7019023\n",
      "0\n",
      "1\n",
      "[INFO] epoch=260,loss=997.5769981\n",
      "0\n",
      "1\n",
      "[INFO] epoch=270,loss=890.4953535\n",
      "0\n",
      "1\n",
      "[INFO] epoch=280,loss=806.4642569\n",
      "0\n",
      "1\n",
      "[INFO] epoch=290,loss=857.3717298\n",
      "0\n",
      "1\n",
      "[INFO] epoch=300,loss=763.3734061\n",
      "0\n",
      "1\n",
      "[INFO] epoch=310,loss=780.8591791\n",
      "0\n",
      "1\n",
      "[INFO] epoch=320,loss=832.6118977\n",
      "0\n",
      "1\n",
      "[INFO] epoch=330,loss=710.0251305\n",
      "0\n",
      "1\n",
      "[INFO] epoch=340,loss=695.0415433\n",
      "0\n",
      "1\n",
      "[INFO] epoch=350,loss=722.8668385\n",
      "0\n",
      "1\n",
      "[INFO] epoch=360,loss=603.0644385\n",
      "0\n",
      "1\n",
      "[INFO] epoch=370,loss=723.3642642\n",
      "0\n",
      "1\n",
      "[INFO] epoch=380,loss=580.4602114\n",
      "0\n",
      "1\n",
      "[INFO] epoch=390,loss=605.3999577\n",
      "0\n",
      "1\n",
      "[INFO] epoch=400,loss=580.7442597\n",
      "0\n",
      "1\n",
      "[INFO] epoch=410,loss=520.7986974\n",
      "0\n",
      "1\n",
      "[INFO] epoch=420,loss=522.5099854\n",
      "0\n",
      "1\n",
      "[INFO] epoch=430,loss=773.6642227\n",
      "0\n",
      "1\n",
      "[INFO] epoch=440,loss=637.0315016\n",
      "0\n",
      "1\n",
      "[INFO] epoch=450,loss=498.8237637\n",
      "0\n",
      "1\n",
      "[INFO] epoch=460,loss=515.1250488\n",
      "0\n",
      "1\n",
      "[INFO] epoch=470,loss=419.2241771\n",
      "0\n",
      "1\n",
      "[INFO] epoch=480,loss=413.5197875\n",
      "0\n",
      "1\n",
      "[INFO] epoch=490,loss=460.7184161\n",
      "0\n",
      "1\n",
      "[INFO] epoch=500,loss=393.5886475\n",
      "0\n",
      "1\n",
      "[INFO] epoch=510,loss=403.1031911\n",
      "0\n",
      "1\n",
      "[INFO] epoch=520,loss=414.2400281\n",
      "0\n",
      "1\n",
      "[INFO] epoch=530,loss=430.2198527\n",
      "0\n",
      "1\n",
      "[INFO] epoch=540,loss=510.3768470\n",
      "0\n",
      "1\n",
      "[INFO] epoch=550,loss=450.6787807\n",
      "0\n",
      "1\n",
      "[INFO] epoch=560,loss=437.1625894\n",
      "0\n",
      "1\n",
      "[INFO] epoch=570,loss=415.4459168\n",
      "0\n",
      "1\n",
      "[INFO] epoch=580,loss=365.6888475\n",
      "0\n",
      "1\n",
      "[INFO] epoch=590,loss=322.5746864\n",
      "0\n",
      "1\n",
      "[INFO] epoch=600,loss=313.4122419\n",
      "0\n",
      "1\n",
      "[INFO] epoch=610,loss=345.0533224\n",
      "0\n",
      "1\n",
      "[INFO] epoch=620,loss=309.2073843\n",
      "0\n",
      "1\n",
      "[INFO] epoch=630,loss=334.3063938\n",
      "0\n",
      "1\n",
      "[INFO] epoch=640,loss=333.2055291\n",
      "0\n",
      "1\n",
      "[INFO] epoch=650,loss=313.9366179\n",
      "0\n",
      "1\n",
      "[INFO] epoch=660,loss=354.2964614\n",
      "0\n",
      "1\n",
      "[INFO] epoch=670,loss=292.1079523\n",
      "0\n",
      "1\n",
      "[INFO] epoch=680,loss=385.0360173\n",
      "0\n",
      "1\n",
      "[INFO] epoch=690,loss=428.5870200\n",
      "0\n",
      "1\n",
      "[INFO] epoch=700,loss=389.2235516\n",
      "0\n",
      "1\n",
      "[INFO] epoch=710,loss=291.6029117\n",
      "0\n",
      "1\n",
      "[INFO] epoch=720,loss=345.2753608\n",
      "0\n",
      "1\n",
      "[INFO] epoch=730,loss=259.0031060\n",
      "0\n",
      "1\n",
      "[INFO] epoch=740,loss=255.7736281\n",
      "0\n",
      "1\n",
      "[INFO] epoch=750,loss=282.3446072\n",
      "0\n",
      "1\n",
      "[INFO] epoch=760,loss=288.6029527\n",
      "0\n",
      "1\n",
      "[INFO] epoch=770,loss=306.8305409\n",
      "0\n",
      "1\n",
      "[INFO] epoch=780,loss=264.3592992\n",
      "0\n",
      "1\n",
      "[INFO] epoch=790,loss=250.6445072\n",
      "0\n",
      "1\n",
      "[INFO] epoch=800,loss=277.6291518\n",
      "0\n",
      "1\n",
      "[INFO] epoch=810,loss=302.7920669\n",
      "0\n",
      "1\n",
      "[INFO] epoch=820,loss=253.1114576\n",
      "0\n",
      "1\n",
      "[INFO] epoch=830,loss=255.5801685\n",
      "0\n",
      "1\n",
      "[INFO] epoch=840,loss=251.0311666\n",
      "0\n",
      "1\n",
      "[INFO] epoch=850,loss=241.1981324\n",
      "0\n",
      "1\n",
      "[INFO] epoch=860,loss=274.7624376\n",
      "0\n",
      "1\n",
      "[INFO] epoch=870,loss=237.2290878\n",
      "0\n",
      "1\n",
      "[INFO] epoch=880,loss=287.0150441\n",
      "0\n",
      "1\n",
      "[INFO] epoch=890,loss=228.5981099\n",
      "0\n",
      "1\n",
      "[INFO] epoch=900,loss=241.4567569\n",
      "0\n",
      "1\n",
      "[INFO] epoch=910,loss=294.0001749\n",
      "0\n",
      "1\n",
      "[INFO] epoch=920,loss=401.7844598\n",
      "0\n",
      "1\n",
      "[INFO] epoch=930,loss=226.9655682\n",
      "0\n",
      "1\n",
      "[INFO] epoch=940,loss=250.2285906\n",
      "0\n",
      "1\n",
      "[INFO] epoch=950,loss=207.8800948\n",
      "0\n",
      "1\n",
      "[INFO] epoch=960,loss=288.9154242\n",
      "0\n",
      "1\n",
      "[INFO] epoch=970,loss=224.6217428\n",
      "0\n",
      "1\n",
      "[INFO] epoch=980,loss=223.4305673\n",
      "0\n",
      "1\n",
      "[INFO] epoch=990,loss=213.1341688\n",
      "0\n",
      "1\n",
      "[INFO] epoch=1000,loss=227.5502157\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([64,16, 10], alpha=0.5) \n",
    "nn.fit(X_train, labels_train,epochs=1000,displayUpdate=10,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(450,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96        45\n",
      "          1       0.94      0.88      0.91        50\n",
      "          2       0.88      1.00      0.93        35\n",
      "          3       0.87      0.91      0.89        44\n",
      "          4       1.00      0.95      0.98        44\n",
      "          5       0.96      0.92      0.94        48\n",
      "          6       0.98      0.93      0.95        43\n",
      "          7       0.98      0.96      0.97        45\n",
      "          8       0.87      0.81      0.84        42\n",
      "          9       0.84      0.91      0.88        54\n",
      "\n",
      "avg / total       0.92      0.92      0.92       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = nn.predict(X_test)\n",
    "predictions = np.argmax(output,axis=1)\n",
    "print(predictions.shape)\n",
    "print(classification_report(predictions,y_test))\n",
    "#这里有一个问题，如果训练的次数少了，会导致有很少部分的数字会出现一次都不会被检测到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 4.64927945e-02, -4.09357781e-02,  3.55406532e-02, ...,\n",
      "        -3.73430415e-02, -7.12649334e-02,  1.04560204e-01],\n",
      "       [ 8.74836084e-01,  1.75334103e-01,  1.16728170e-01, ...,\n",
      "         1.24605372e-01,  7.91870234e-01,  4.45577082e-02],\n",
      "       [-3.28083543e+00, -2.64937463e-02, -1.86041510e-01, ...,\n",
      "         1.09375460e-01,  9.29422385e-01, -5.86639767e-01],\n",
      "       ...,\n",
      "       [-6.85402741e-01, -1.54053632e-02, -2.48776056e-01, ...,\n",
      "        -8.23282896e-02,  1.41198832e+01, -4.76326611e-02],\n",
      "       [ 1.60414712e+00, -3.73207467e-02, -7.33364615e-02, ...,\n",
      "        -2.12909308e-01,  9.48703112e+00, -1.09630491e-01],\n",
      "       [ 2.70350060e-01, -2.25362948e-01, -1.13343680e-02, ...,\n",
      "        -5.75325854e-02,  4.17241462e-01,  9.44890633e-02]]), array([[-7.92071347e+00,  2.84134570e+00, -7.58362479e+00,\n",
      "        -3.40684136e+00,  5.44923732e+00,  3.72950892e+00,\n",
      "         7.43916294e+00,  4.38996797e+00,  3.44688166e+00,\n",
      "        -2.40683980e+00],\n",
      "       [ 2.22692812e-01,  1.50954306e-02, -1.02348240e-01,\n",
      "        -7.54198641e-02, -7.49499685e-02, -4.99254118e-01,\n",
      "         2.07801923e-01, -1.79924533e-01, -1.57055182e-01,\n",
      "        -1.98577616e-01],\n",
      "       [ 2.83914066e-01, -1.90221989e+00, -1.84696058e+00,\n",
      "        -1.05322083e+00, -1.78269518e+00, -1.26967808e+00,\n",
      "        -8.96317598e-01, -2.01810718e+00, -1.44906170e+00,\n",
      "        -6.72129697e-01],\n",
      "       [ 2.35850132e-01,  5.91258186e-01,  1.48289473e-01,\n",
      "        -3.80248523e-02, -2.24378207e-01, -1.24372774e-01,\n",
      "        -2.40804821e-01, -1.26951429e-01, -8.69913388e-03,\n",
      "        -4.50493713e-01],\n",
      "       [ 1.18770649e-01,  5.06788200e-01,  2.06720204e-01,\n",
      "        -1.45183907e-01, -4.86255884e-01, -4.51171949e-01,\n",
      "         3.58350798e-01, -2.52591522e-01, -4.26234721e-01,\n",
      "         3.71966393e-01],\n",
      "       [ 1.46215563e-01, -1.70810440e-01,  1.30506569e-01,\n",
      "         2.03123400e-01, -1.69833330e-01,  4.38149371e-01,\n",
      "         3.18111168e-02,  1.31931696e-03, -7.75407525e-02,\n",
      "        -1.12881905e-01],\n",
      "       [-3.90018184e-01,  1.60270035e-01,  1.58033206e-01,\n",
      "         2.02134597e-01,  2.42448318e-01,  7.03729157e-02,\n",
      "        -6.36869644e-02, -2.56246710e-02, -2.71169089e-01,\n",
      "        -8.30968729e-02],\n",
      "       [-8.53945155e+00,  3.78641893e+00,  4.81310850e+00,\n",
      "         4.16190695e+00, -7.26710541e+00,  4.50656606e+00,\n",
      "        -7.62351392e+00,  4.57878433e+00,  3.84334253e+00,\n",
      "         4.64686580e+00],\n",
      "       [-8.93548654e-02, -1.35363944e+00, -2.96437994e-01,\n",
      "        -8.23860564e-01,  1.04677932e+00, -5.39197071e-01,\n",
      "        -1.22875049e-01,  2.62669156e+00, -1.43064854e-01,\n",
      "         1.99664295e-01],\n",
      "       [ 1.79247354e+00, -5.87775797e-01, -1.22480090e+00,\n",
      "         1.11701953e+00, -9.36425364e-01, -1.03340036e+00,\n",
      "        -9.95541622e-01, -1.00049312e+00, -6.52532961e-01,\n",
      "         1.69793552e+00],\n",
      "       [ 1.14040239e+00, -3.40327830e+00, -2.62903521e+00,\n",
      "        -1.34136865e+00, -2.23316853e+00, -3.15392503e+00,\n",
      "        -1.51831560e+00, -4.16032894e+00, -2.47674525e+00,\n",
      "        -1.43091273e+00],\n",
      "       [ 1.38786888e+00, -3.21416699e+00, -2.40517808e+00,\n",
      "        -1.69050970e+00, -2.94142388e+00, -2.53281653e+00,\n",
      "        -1.04615930e+00, -4.07498613e+00, -2.28818209e+00,\n",
      "        -1.22283262e+00],\n",
      "       [-2.85194657e-01, -9.01281745e-01, -5.04489698e-01,\n",
      "        -8.21658251e-01, -8.05471709e-01,  3.82712971e-01,\n",
      "        -9.44225925e-01, -1.35251077e+00, -5.37595654e-01,\n",
      "         1.41006352e-02],\n",
      "       [ 4.17369433e+00, -1.53412717e+00, -2.40553756e-01,\n",
      "        -8.47183230e-01,  5.36836859e-01, -2.36380802e+00,\n",
      "         1.45381692e+00, -1.95779644e+00, -4.88963609e-01,\n",
      "        -4.80635454e-01],\n",
      "       [ 1.23763771e+00, -3.09635213e+00, -3.05153152e+00,\n",
      "        -1.22717930e+00, -2.92618202e+00, -2.89427197e+00,\n",
      "        -1.08508378e+00, -4.31644165e+00, -2.21191550e+00,\n",
      "        -1.31871148e+00],\n",
      "       [-1.00478784e+00,  2.63048280e+00,  5.54491898e+00,\n",
      "        -3.01063968e+00,  6.94177794e+00, -6.86018155e+00,\n",
      "        -6.13475367e+00,  4.05837833e+00, -8.80585044e-01,\n",
      "        -3.95105017e+00],\n",
      "       [-4.70882097e-01,  1.02925047e+00, -7.92475273e-01,\n",
      "        -5.25664991e-01,  2.04016060e+00, -5.08385424e-01,\n",
      "        -7.70049465e-01, -1.66048599e-01, -2.71711530e-02,\n",
      "         6.23661101e-01]])]\n"
     ]
    }
   ],
   "source": [
    "print(nn.W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
